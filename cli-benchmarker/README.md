# CLI Benchmarker

[![PyPI version](https://badge.fury.io/py/cli-benchmarker.svg)](https://pypi.org/project/cli-benchmarker/) [![Tests](https://github.com/cycoders/code/actions/workflows/ci.yml/badge.svg?branch=main&event=push)](https://github.com/cycoders/code/actions/workflows/ci.yml)

## Why this exists

Optimizing CLI tools, build scripts, and shell workflows is crucial for developer productivity. Tools like `hyperfine` excel at wall-clock timing but ignore CPU utilization and memory footprintâ€”key bottlenecks in real-world scenarios like `npm install`, `docker build`, or custom scripts. **CLI Benchmarker** delivers **holistic metrics** with rigorous statistics (mean Â± std, median, P95), failure tolerance, timeouts, and publication-quality terminal output using Rich. Track regressions across git commits and export JSON for dashboards.

Built for senior engineers who demand precision without complexity.

## Features

- ğŸƒ **Multi-command comparison**: Benchmark `cmd1` vs `cmd2` side-by-side
- â±ï¸ **Wall time** + **CPU time** (user/sys/children) + **peak RSS memory**
- ğŸ“Š **Statistics**: mean, std dev, median, P95, min/max + distribution sparklines
- ğŸš€ **Warmup runs** to stabilize caches/JIT
- ğŸ›¡ï¸ **Timeouts** & failure reporting (exit codes, verbose stdout/stderr)
- ğŸ¨ **Rich tables** & progress bars
- ğŸ“¤ **JSON export** for CI/parsing
- ğŸ”„ **Cross-platform** (Linux/macOS/Windows via psutil)

## Benchmarks vs Alternatives

| Feature          | CLI Benchmarker | hyperfine | /usr/bin/time |
|------------------|-----------------|-----------|---------------|
| Wall time        | âœ…              | âœ…        | âœ…            |
| CPU time         | âœ…              | âŒ        | Partial      |
| Peak memory      | âœ…              | âŒ        | âŒ            |
| P95/Stats        | âœ… Full         | Basic    | âŒ            |
| Sparklines/Viz   | âœ… Rich         | Basic    | âŒ            |
| Multi-cmd        | âœ…              | âœ…        | âŒ            |
| JSON export      | âœ…              | âŒ        | âŒ            |

Example on `npm ci` (30 runs, M2 Mac):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Command     â”‚ Runs â”‚   Mean   â”‚ Â± â”‚  Median  â”‚  P95 â”‚ Min  â”‚ Max [spark]  â”‚ CPU  â”‚    Mem     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ npm ci      â”‚ 30/30â”‚ 2450ms   â”‚67 â”‚ 2432ms   â”‚ 2601 â”‚ 2356 â”‚ 2678 [â–â–‚â–„â–„â–…â–…â–†â–‡â–ˆ]â”‚ 1.8s â”‚ 245.2/312MBâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Installation

```
pip install cli-benchmarker
```

Or from source:

```
git clone https://github.com/cycoders/code
cd cli-benchmarker
python -m venv venv
source venv/bin/activate  # Linux/macOS
pip install -e ".[dev]"
```

## Usage

### Single command

```bash
cli-benchmarker run "npm run build"
```

### Compare commands

```bash
cli-benchmarker run "docker build ." "docker build . --no-cache"
```

### Advanced

```bash
cli-benchmarker run "git status" \
  --warmup 5 --runs 50 --timeout 2.0 --json results.json --verbose
```

Full help:

```bash
cli-benchmarker run --help
```

**Pro tip**: Alias `cb=cli-benchmarker run` and pipe to `tee` for records.

## Examples

See `examples/` for `npm`/`docker`/`rustc` workflows.

## Architecture

```
CLI (Typer)
  â†“
Benchmarker (subprocess + psutil sampling)
  â†“
Metrics: {wall_time, cpu_total, mem_peak, success}
  â†“
Stats (statistics.stdlib) + Sparklines
  â†“
Rich Table (console)
```

- Sampling thread for real-time peak memory (20ms poll)
- Handles timeouts/kills gracefully
- Only successful runs in stats (failed noted)

## Alternatives considered

| Tool       | Why not? |
|------------|----------|
| hyperfine  | No CPU/mem/stats depth |
| time(1)    | No viz/repeat/stats |
| custom bash| Reinvent wheel, error-prone |

CLI Benchmarker is 100% Python stdlib + minimal deps, zero config.

## Development

```
pytest
ruff check .
ruff format .
```

## License

MIT Â© 2025 Arya Sianati

---

â­ Love it? [Star the monorepo](https://github.com/cycoders/code)!